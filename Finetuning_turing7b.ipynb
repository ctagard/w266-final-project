{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd99f3f-369e-498e-a70a-57580e28bf07",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d8906b-4e5c-4ba0-9d5f-28457c3a00b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 13:22:22.119924: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-09 13:22:22.119954: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-09 13:22:22.121019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-09 13:22:22.126533: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-09 13:22:22.806008: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/turing/Documents/turing/turingenv/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed2afb5-1818-4174-a666-97712fc57e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c96e7d-ea2c-40ef-aa5d-68bd1131ac4d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6762134-f6c1-4c47-9fe6-0589a5f8b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"FinalInstructImproved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b0b541-ded4-4a3b-a8f1-2867a203c2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Notebook</th>\n",
       "      <th>Position</th>\n",
       "      <th>ExtractedPrompt</th>\n",
       "      <th>ImprovedPrompt</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1481</td>\n",
       "      <td>1</td>\n",
       "      <td># Generating text for NLP using SimpleRNN with...</td>\n",
       "      <td>Write Python code to import the following libr...</td>\n",
       "      <td># This Python 3 environment comes with many he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1481</td>\n",
       "      <td>2</td>\n",
       "      <td>## 2. Import data and preprocessing.\\n\\nWe rea...</td>\n",
       "      <td>Write Python code to read a text file named \"a...</td>\n",
       "      <td>fin = open(\"../input/alice_in_wonderland.txt\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1481</td>\n",
       "      <td>3</td>\n",
       "      <td>The next step is to create the input and label...</td>\n",
       "      <td>Write Python code to create two lists, input_c...</td>\n",
       "      <td>SEQLEN = 10\\nSTEP = 1\\ninput_chars = []\\nlabel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1481</td>\n",
       "      <td>4</td>\n",
       "      <td>The next step is to vectorize these input and ...</td>\n",
       "      <td>Write Python code to create two arrays, X and ...</td>\n",
       "      <td>X = np.zeros((len(input_chars), SEQLEN, nb_cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1481</td>\n",
       "      <td>5</td>\n",
       "      <td>## 3. Model Building.\\n\\n* We define the RNN's...</td>\n",
       "      <td>Write Python code to define a Sequential model...</td>\n",
       "      <td>HIDDEN_SIZE = 128\\nBATCH_SIZE = 128\\nNUM_ITERA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Notebook  Position  \\\n",
       "0           0      1481         1   \n",
       "1           1      1481         2   \n",
       "2           2      1481         3   \n",
       "3           3      1481         4   \n",
       "4           4      1481         5   \n",
       "\n",
       "                                     ExtractedPrompt  \\\n",
       "0  # Generating text for NLP using SimpleRNN with...   \n",
       "1  ## 2. Import data and preprocessing.\\n\\nWe rea...   \n",
       "2  The next step is to create the input and label...   \n",
       "3  The next step is to vectorize these input and ...   \n",
       "4  ## 3. Model Building.\\n\\n* We define the RNN's...   \n",
       "\n",
       "                                      ImprovedPrompt  \\\n",
       "0  Write Python code to import the following libr...   \n",
       "1  Write Python code to read a text file named \"a...   \n",
       "2  Write Python code to create two lists, input_c...   \n",
       "3  Write Python code to create two arrays, X and ...   \n",
       "4  Write Python code to define a Sequential model...   \n",
       "\n",
       "                                                Code  \n",
       "0  # This Python 3 environment comes with many he...  \n",
       "1  fin = open(\"../input/alice_in_wonderland.txt\",...  \n",
       "2  SEQLEN = 10\\nSTEP = 1\\ninput_chars = []\\nlabel...  \n",
       "3  X = np.zeros((len(input_chars), SEQLEN, nb_cha...  \n",
       "4  HIDDEN_SIZE = 128\\nBATCH_SIZE = 128\\nNUM_ITERA...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c37f6bf8-82e5-49a9-a986-65aa8bcddfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Data Science Expert. Write the python code outlined in the instruction below.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df2394f-e6f5-44e9-a301-c5414bf210e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7bd744a-6e4a-4b58-835e-8e8049ac183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unclean, test_unclean = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ab4a18-ee8f-4cf6-8149-cadaaa06e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unclean, val_unclean = train_test_split(train_unclean, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70c14c5-cb76-4a9b-a534-c330b95bb140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (6696, 6)\n",
      "val shape: (745, 6)\n",
      "test shape: (1861, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train shape: {train_unclean.shape}\")\n",
    "print(f\"val shape: {val_unclean.shape}\")\n",
    "print(f\"test shape: {test_unclean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a3847a-fd4d-41dd-8a97-2275532f5de8",
   "metadata": {},
   "source": [
    "## Add column to dataframe with formatted instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63221f9f-3202-462e-8120-dbaefd32f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, test=False):\n",
    "    data = df.copy()\n",
    "    def format_instruction(row, test):\n",
    "        if test: \n",
    "            return f\"\"\"\n",
    "        <s>[INST] <<SYS>>\\nYou are an expert in Data Science. Below is an instruction that describes a task. Write Python code that appropriately completes the request. Please wrap your code using ```.\\n<</SYS>>\\n\\n{row['ImprovedPrompt']}[/INST]\n",
    "        \"\"\".strip()\n",
    "        return f\"\"\"\n",
    "        <s>[INST] <<SYS>>\\nYou are an expert in Data Science. Below is an instruction that describes a task. Write Python code that appropriately completes the request. Please wrap your code using ```.\\n<</SYS>>\\n\\n{row['ImprovedPrompt']}[/INST] ```\\n{row['Code']}\\n``` </s>\n",
    "        \"\"\".strip()\n",
    "    data['text'] = data.apply(lambda x: format_instruction(x, test), axis=1)\n",
    "    if test:\n",
    "        data['baseline_non_instruct'] = data.apply(lambda x: format_instruction(x, test), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56b9411-06b2-4665-99c4-40433918ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = process_dataframe(train_unclean)\n",
    "val_df = process_dataframe(val_unclean)\n",
    "test_df = process_dataframe(test_unclean, test=True)\n",
    "test_df.to_csv(\"../experiments/test_formatted.csv\")\n",
    "train = Dataset.from_pandas(train_df)\n",
    "val = Dataset.from_pandas(val_df)\n",
    "test = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "382f52d1-042e-4d55-a866-0f9f4ecaf4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Notebook</th>\n",
       "      <th>Position</th>\n",
       "      <th>ExtractedPrompt</th>\n",
       "      <th>ImprovedPrompt</th>\n",
       "      <th>Code</th>\n",
       "      <th>text</th>\n",
       "      <th>baseline_non_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6032</td>\n",
       "      <td>6145</td>\n",
       "      <td>1771</td>\n",
       "      <td>5</td>\n",
       "      <td>## Section 1.3 Resize, Flip and Rotate ### Sub...</td>\n",
       "      <td>Write Python code to read an image file named ...</td>\n",
       "      <td>lena_rgb = cv2.imread(lena, cv2.IMREAD_UNCHANG...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1112</td>\n",
       "      <td>1138</td>\n",
       "      <td>2087</td>\n",
       "      <td>5</td>\n",
       "      <td>Since we are all here to learn, let's explore ...</td>\n",
       "      <td>Write Python code to extract the advice from a...</td>\n",
       "      <td>advice = quote[quote.new_question == 562]\\npri...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7990</td>\n",
       "      <td>8133</td>\n",
       "      <td>3014</td>\n",
       "      <td>29</td>\n",
       "      <td>- From the above visualization we can see that...</td>\n",
       "      <td>Write Python code to import the Seaborn librar...</td>\n",
       "      <td>ax = sns.countplot(x=df.Alcoholism, hue=df.NoS...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8271</td>\n",
       "      <td>8418</td>\n",
       "      <td>3021</td>\n",
       "      <td>5</td>\n",
       "      <td>### Numerical Variables</td>\n",
       "      <td>Write Python code to create a figure with a si...</td>\n",
       "      <td>plt.figure(figsize=(14, len(num_cols) * 3))\\n\\...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6352</td>\n",
       "      <td>6469</td>\n",
       "      <td>2548</td>\n",
       "      <td>18</td>\n",
       "      <td># Some Resources:* https://keras.io/\\n* https:...</td>\n",
       "      <td>Write Python code to import the IPython.displa...</td>\n",
       "      <td>from IPython.display import display, HTML\\n\\nc...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert in Data S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  Notebook  Position  \\\n",
       "0          6032        6145      1771         5   \n",
       "1          1112        1138      2087         5   \n",
       "2          7990        8133      3014        29   \n",
       "3          8271        8418      3021         5   \n",
       "4          6352        6469      2548        18   \n",
       "\n",
       "                                     ExtractedPrompt  \\\n",
       "0  ## Section 1.3 Resize, Flip and Rotate ### Sub...   \n",
       "1  Since we are all here to learn, let's explore ...   \n",
       "2  - From the above visualization we can see that...   \n",
       "3                            ### Numerical Variables   \n",
       "4  # Some Resources:* https://keras.io/\\n* https:...   \n",
       "\n",
       "                                      ImprovedPrompt  \\\n",
       "0  Write Python code to read an image file named ...   \n",
       "1  Write Python code to extract the advice from a...   \n",
       "2  Write Python code to import the Seaborn librar...   \n",
       "3  Write Python code to create a figure with a si...   \n",
       "4  Write Python code to import the IPython.displa...   \n",
       "\n",
       "                                                Code  \\\n",
       "0  lena_rgb = cv2.imread(lena, cv2.IMREAD_UNCHANG...   \n",
       "1  advice = quote[quote.new_question == 562]\\npri...   \n",
       "2  ax = sns.countplot(x=df.Alcoholism, hue=df.NoS...   \n",
       "3  plt.figure(figsize=(14, len(num_cols) * 3))\\n\\...   \n",
       "4  from IPython.display import display, HTML\\n\\nc...   \n",
       "\n",
       "                                                text  \\\n",
       "0  <s>[INST] <<SYS>>\\nYou are an expert in Data S...   \n",
       "1  <s>[INST] <<SYS>>\\nYou are an expert in Data S...   \n",
       "2  <s>[INST] <<SYS>>\\nYou are an expert in Data S...   \n",
       "3  <s>[INST] <<SYS>>\\nYou are an expert in Data S...   \n",
       "4  <s>[INST] <<SYS>>\\nYou are an expert in Data S...   \n",
       "\n",
       "                               baseline_non_instruct  \n",
       "0  <s>[INST] <<SYS>>\\nYou are an expert in Data S...  \n",
       "1  <s>[INST] <<SYS>>\\nYou are an expert in Data S...  \n",
       "2  <s>[INST] <<SYS>>\\nYou are an expert in Data S...  \n",
       "3  <s>[INST] <<SYS>>\\nYou are an expert in Data S...  \n",
       "4  <s>[INST] <<SYS>>\\nYou are an expert in Data S...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../experiments/test_formatted.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3d01f-7f9b-4568-be3d-848226c38f71",
   "metadata": {},
   "source": [
    "# Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0fb37a1-db1d-4e33-8829-6ad50175e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "OUTPUT_DIR = \"turing-7b-2epoch-12-08-2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56c62c29-04b9-489c-8f5a-f6770f2cc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_tokenizer():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        use_safetensors=True,\n",
    "        quantization_config=bnb_config,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebd98ef1-5af2-4f48-99de-fb52f10970e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bbcdd1d7d346e68bcab9720460b1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = create_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d473086-1a14-4cb1-90c8-3cf136504042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_method': <QuantizationMethod.BITS_AND_BYTES: 'bitsandbytes'>,\n",
       " 'load_in_8bit': False,\n",
       " 'load_in_4bit': True,\n",
       " 'llm_int8_threshold': 6.0,\n",
       " 'llm_int8_skip_modules': None,\n",
       " 'llm_int8_enable_fp32_cpu_offload': False,\n",
       " 'llm_int8_has_fp16_weight': False,\n",
       " 'bnb_4bit_quant_type': 'nf4',\n",
       " 'bnb_4bit_use_double_quant': False,\n",
       " 'bnb_4bit_compute_dtype': 'float16'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.quantization_config.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db930817-9a4a-4934-bfe5-7097f72d3165",
   "metadata": {},
   "source": [
    "## LORA config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d105524-05e4-490a-be26-fa215773efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_alpha = 16\n",
    "lora_dropout = 0.05\n",
    "lora_r = 8\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha, \n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e9a32-5747-4ba9-852e-e601bbd6d8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f44f7fe6-2068-43ce-9434-e7b3c8659abf",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3efa97e-2c2c-4a44-9705-12f0f89df1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    report_to=\"tensorboard\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    seed=42,\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77dbb9e2-33c1-444f-8f82-a78ab97c0211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc302bdfc1ea4cdca25a4c3c2b5838e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6696 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b7ec5082724d288a63954363e701e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/745 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f2390-02a5-44af-8e1c-c85238817bc2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddcd74df-59ab-4ea8-a096-4cb4ed823047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeLlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1254' max='1254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1254/1254 1:42:54, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.596497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>0.557380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>0.558200</td>\n",
       "      <td>0.544338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1004</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.539134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1254, training_loss=0.5681097306655735, metrics={'train_runtime': 6184.9766, 'train_samples_per_second': 3.248, 'train_steps_per_second': 0.203, 'total_flos': 3.359670957246382e+17, 'train_loss': 0.5681097306655735, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd2d9807-4a85-4c00-8b01-0be4b5f96f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af6673e4-8427-45ca-87ea-ac32241b4da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb77ae2330f40baa2f757edaa12a78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('merged_model_train_cole/tokenizer_config.json',\n",
       " 'merged_model_train_cole/special_tokens_map.json',\n",
       " 'merged_model_train_cole/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "trained_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    OUTPUT_DIR,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "merged_model = trained_model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"merged_model_train_cole\", safe_serialization=True)\n",
    "tokenizer.save_pretrained(\"merged_model_train_cole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e5451-bc30-40a2-bd12-2886d5cfbf5a",
   "metadata": {},
   "source": [
    "## Run on one example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa10bf0-c7be-4207-85a0-ee20209c6bed",
   "metadata": {},
   "source": [
    "Okay I found the issue. We have to RELOAD the model WITHOUT peft or any funny business, before loading it with PEFT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ad8e9-a75c-4df1-b27d-f357953890c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = create_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a0fe6-82db-44ff-80c8-ea8a111e4b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = PeftModel.from_pretrained(model, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f15ef8-0953-40b6-85f9-13e1bffb1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test['text'][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706e3a0-a364-4421-85f2-1194f482c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer(test_text, return_tensors='pt').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885fac4-b569-4abe-9b15-8e468d9be1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with torch.inference_mode():\n",
    "    toks = trained_model.generate(**tokenized_test, max_new_tokens=1024)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578abb17-0851-44dd-9095-1329622df31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tokenizer.decode(toks, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef21790-4cf6-45ed-8837-a29569134fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e9f2b-0d74-408e-8189-ffbfff7539d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "315ab1a4-7c4e-4016-9f3e-f3d961fac338",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
