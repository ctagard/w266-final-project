{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-16T01:16:22.628187Z",
     "start_time": "2023-11-16T01:16:22.626414Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"processed_kernels_with_indices_1.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T01:16:23.489300Z",
     "start_time": "2023-11-16T01:16:23.327114Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(14701, 4)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T01:16:24.659698Z",
     "start_time": "2023-11-16T01:16:24.654706Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of your CSV files\n",
    "csv_files = [\n",
    "    'processed_kernels_with_indices.csv',\n",
    "    'processed_kernels_with_indices_1.csv',\n",
    "    'processed_kernels_with_indices_2.csv',\n",
    "    'processed_kernels_with_indices_eda.csv',\n",
    "    'processed_kernels_with_indices_ethics.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Process each file\n",
    "for i, file in enumerate(csv_files):\n",
    "    # Read the file\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Temporarily adjust the 'Notebook' column to create a unique identifier\n",
    "    df['Notebook'] += i * 10000  # Assuming no single file has more than 10,000 notebooks\n",
    "\n",
    "    # Append to the main DataFrame\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "# Remove duplicate rows based on 'Prompt' and 'Example' columns\n",
    "all_data = all_data.drop_duplicates(subset=['Prompt', 'Example'])\n",
    "\n",
    "# Renumber the 'Notebook' column\n",
    "unique_notebooks = sorted(all_data['Notebook'].unique())\n",
    "notebook_mapping = {nb: i + 1 for i, nb in enumerate(unique_notebooks)}\n",
    "all_data['Notebook'] = all_data['Notebook'].map(notebook_mapping)\n",
    "\n",
    "# Reset the index\n",
    "all_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save to a new CSV file\n",
    "all_data.to_csv('processed_kernels_combined.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:25:38.245054Z",
     "start_time": "2023-11-16T18:25:36.522190Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(60138, 4)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"processed_kernels_combined.csv\")\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:25:39.785109Z",
     "start_time": "2023-11-16T18:25:39.064344Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "    Notebook  Position                                             Prompt  \\\n0          1         1  If this notebook was helpful to you in any way...   \n1          1         2  \\n# Setting Things Up\\nWe define the file path...   \n2          1         3  \\nFinally, we define custom dataset class for ...   \n3          1         4  \\n# Datasets and Dataloaders Setup\\n\\n\\nNow we...   \n4          1         5           \\n# Creating a Convolutional Network\\n\\n   \n..       ...       ...                                                ...   \n85         5        27  ## Final Scores in Away Games by Teams\\n\\nLet'...   \n86         5        28  # Insights from Tackles Data\\n\\nLet's review t...   \n87         5        29  ## Tackles per Game\\n\\nLet's look at the distr...   \n88         5        30  We see that the distribution of the number of ...   \n89         5        31  We find  that\\n- the Q1 value is `67` tackles ...   \n\n                                              Example  \n0   # Importing necessary libraries and modules\\ni...  \n1   # Defining the paths for the training and test...  \n2   # Defining a custom dataset class for loading ...  \n3   # Creating instances of the manualDataset clas...  \n4   class CNN(nn.Module):\\n    def __init__(self):...  \n..                                                ...  \n85  agg_dict_2 = {\\n    \"min_away_score\": pd.Named...  \n86  tackles.head().style.set_caption(\"Sample of th...  \n87  tackle_games = tackles.groupby([\"gameId\"])[\"ta...  \n88  fig = px.box(\\n    agg_data,\\n    x=\"tackles\",...  \n89  agg_data.sort_values([\"tackles\"], ascending=Fa...  \n\n[90 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Notebook</th>\n      <th>Position</th>\n      <th>Prompt</th>\n      <th>Example</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>If this notebook was helpful to you in any way...</td>\n      <td># Importing necessary libraries and modules\\ni...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>\\n# Setting Things Up\\nWe define the file path...</td>\n      <td># Defining the paths for the training and test...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>\\nFinally, we define custom dataset class for ...</td>\n      <td># Defining a custom dataset class for loading ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>\\n# Datasets and Dataloaders Setup\\n\\n\\nNow we...</td>\n      <td># Creating instances of the manualDataset clas...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>\\n# Creating a Convolutional Network\\n\\n</td>\n      <td>class CNN(nn.Module):\\n    def __init__(self):...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>5</td>\n      <td>27</td>\n      <td>## Final Scores in Away Games by Teams\\n\\nLet'...</td>\n      <td>agg_dict_2 = {\\n    \"min_away_score\": pd.Named...</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>5</td>\n      <td>28</td>\n      <td># Insights from Tackles Data\\n\\nLet's review t...</td>\n      <td>tackles.head().style.set_caption(\"Sample of th...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>5</td>\n      <td>29</td>\n      <td>## Tackles per Game\\n\\nLet's look at the distr...</td>\n      <td>tackle_games = tackles.groupby([\"gameId\"])[\"ta...</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>5</td>\n      <td>30</td>\n      <td>We see that the distribution of the number of ...</td>\n      <td>fig = px.box(\\n    agg_data,\\n    x=\"tackles\",...</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>5</td>\n      <td>31</td>\n      <td>We find  that\\n- the Q1 value is `67` tackles ...</td>\n      <td>agg_data.sort_values([\"tackles\"], ascending=Fa...</td>\n    </tr>\n  </tbody>\n</table>\n<p>90 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(90)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:41:38.294696Z",
     "start_time": "2023-11-16T18:41:38.290649Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"processed_kernels_combined.csv\")\n",
    "\n",
    "# Group by 'Notebook' and create a list of dataframes\n",
    "grouped = data.groupby('Notebook')\n",
    "df_list = [grouped.get_group(x) for x in grouped.groups]\n",
    "\n",
    "# Split the list of dataframes\n",
    "train_list, test_val_list = train_test_split(df_list, test_size=0.3, random_state=42)\n",
    "val_list, test_list = train_test_split(test_val_list, test_size=0.5, random_state=42)\n",
    "\n",
    "# Concatenate lists back into DataFrames\n",
    "train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "val_df = pd.concat(val_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV files\n",
    "train_df.to_csv(\"processed_kernels_train.csv\", index=False)\n",
    "val_df.to_csv(\"processed_kernels_val.csv\", index=False)\n",
    "test_df.to_csv(\"processed_kernels_test.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:35:41.032018Z",
     "start_time": "2023-11-19T20:35:38.297016Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:46:29.966584Z",
     "start_time": "2023-11-19T20:46:26.669559Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f3e8b15896f4e65b6eafbb8b39f0f2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0aec60e0be3a43a9ae6338d7ac550ee1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c26c1d0e12940569124bafeb5dd812d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating val split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bdb85bcff5148768bd9cc6ec60d6be4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6de9d03770fb4447810a16b67daec5d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files={\"train\": \"processed_kernels_train.csv\", \"val\": \"processed_kernels_val.csv\", \"test\": \"processed_kernels_test.csv\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:48:42.550331Z",
     "start_time": "2023-11-19T20:48:41.400650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ade36bc37d034736896cde51e610c0d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/42 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87068377de2e4c7698bc9d53d926c900"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ac108ad634d486e9859188d63300c70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f3dff5aed764d2abaebc97e336ae608"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de548b10cef143eeb08c2cd69e898753"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79844da4d6aa433aafc49300f0d25ee5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "README.md:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff6dde7376214f2886cf4849b132b1bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"w266finalproject/turing-60k-instruct\", token=\"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\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:55:37.985776Z",
     "start_time": "2023-11-19T20:55:10.858119Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
